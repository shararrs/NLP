{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Uncomment the lines below if running on google collab\n",
    "# As we have to manually upload the csv file called 'federalist.csv'\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#from google.colab import files\n",
    "#uploaded = files.upload() # used to upload a file to the google drive"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     author                                               text\n",
      "0  HAMILTON  FEDERALIST. No. 1 General Introduction For the...\n",
      "1       JAY  FEDERALIST No. 2 Concerning Dangers from Forei...\n",
      "2       JAY  FEDERALIST No. 3 The Same Subject Continued (C...\n",
      "3       JAY  FEDERALIST No. 4 The Same Subject Continued (C...\n",
      "4       JAY  FEDERALIST No. 5 The Same Subject Continued (C...\n",
      "5  HAMILTON  FEDERALIST No. 6 Concerning Dangers from Disse...\n",
      "6  HAMILTON  FEDERALIST. No. 7 The Same Subject Continued (...\n",
      "7  HAMILTON  FEDERALIST No. 8 The Consequences of Hostiliti...\n",
      "8  HAMILTON  FEDERALIST No. 9 The Union as a Safeguard Agai...\n",
      "9   MADISON  FEDERALIST No. 10 The Same Subject Continued (...\n",
      "author\n",
      "HAMILTON                49\n",
      "HAMILTON AND MADISON     3\n",
      "HAMILTON OR MADISON     11\n",
      "JAY                      5\n",
      "MADISON                 15\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('federalist.csv')\n",
    "df['author'] = pd.Categorical(df.author)\n",
    "print(df.head(10))\n",
    "dfx = df.groupby(['author'])['author'].count()\n",
    "print(dfx)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is (83,), X train is (66,) and X test is (17,)\n",
      "The shape of Y is (83,), Y train is (66,) and Y test is (17,)\n"
     ]
    }
   ],
   "source": [
    "X = df.text\n",
    "Y = df.author\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, train_size=0.8, random_state=1234)\n",
    "\n",
    "print(f\"The shape of X is {X.shape}, X train is {X_train.shape} and X test is {X_test.shape}\")\n",
    "print(f\"The shape of Y is {Y.shape}, Y train is {Y_train.shape} and Y test is {Y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape - (66, 7876)\n",
      "Test set shape - (17, 7876)\n"
     ]
    }
   ],
   "source": [
    "stopwords = stopwords.words('english')\n",
    "stopwords = set(stopwords)\n",
    "tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "X_train_set = tf_idf.fit_transform(X_train)\n",
    "X_test_set = tf_idf.transform(X_test)\n",
    "print(f\"Training set shape - {X_train_set.shape}\")\n",
    "print(f\"Test set shape - {X_test_set.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.5882352941176471\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.59      1.00      0.74        10\n",
      "HAMILTON OR MADISON       0.00      0.00      0.00         3\n",
      "                JAY       0.00      0.00      0.00         2\n",
      "            MADISON       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.59        17\n",
      "          macro avg       0.15      0.25      0.19        17\n",
      "       weighted avg       0.35      0.59      0.44        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bernoulli = BernoulliNB()\n",
    "bernoulli.fit(X_train_set, Y_train)\n",
    "pred = bernoulli.predict(X_test_set)\n",
    "print('accuracy score: ', accuracy_score(Y_test, pred))\n",
    "print(classification_report(Y_test, pred, zero_division=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape - (66, 1000)\n",
      "Test set shape - (17, 1000)\n",
      "_____________________________________________________________\n",
      "\n",
      " accuracy score:  0.9411764705882353\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.91      1.00      0.95        10\n",
      "HAMILTON OR MADISON       1.00      1.00      1.00         3\n",
      "                JAY       1.00      0.50      0.67         2\n",
      "            MADISON       1.00      1.00      1.00         2\n",
      "\n",
      "           accuracy                           0.94        17\n",
      "          macro avg       0.98      0.88      0.90        17\n",
      "       weighted avg       0.95      0.94      0.93        17\n",
      "\n",
      "_____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ngram_range=(1,2) uses unigrams and bigrams\n",
    "tf_idf_update = TfidfVectorizer(stop_words=stopwords,ngram_range=(1,2), max_features=1000)\n",
    "X_train_set = tf_idf_update.fit_transform(X_train)\n",
    "X_test_set = tf_idf_update.transform(X_test)\n",
    "print(f\"\\nTraining set shape - {X_train_set.shape}\")\n",
    "print(f\"Test set shape - {X_test_set.shape}\")\n",
    "naive_bayes = BernoulliNB()\n",
    "naive_bayes.fit(X_train_set, Y_train)\n",
    "pred = naive_bayes.predict(X_test_set)\n",
    "print(\"_____________________________________________________________\")\n",
    "print('\\n accuracy score: ', accuracy_score(Y_test, pred))\n",
    "print(classification_report(Y_test, pred, zero_division=0))\n",
    "print(\"_____________________________________________________________\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression no param__________________________________\n",
      "\n",
      " accuracy score:  0.5882352941176471\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.59      1.00      0.74        10\n",
      "HAMILTON OR MADISON       0.00      0.00      0.00         3\n",
      "                JAY       0.00      0.00      0.00         2\n",
      "            MADISON       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.59        17\n",
      "          macro avg       0.15      0.25      0.19        17\n",
      "       weighted avg       0.35      0.59      0.44        17\n",
      "\n",
      "_____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ngram_range=(1,2) uses unigrams and bigrams\n",
    "tf_idf_update = TfidfVectorizer(stop_words=stopwords,ngram_range=(1,2), max_features=1000)\n",
    "X_train_set = tf_idf_update.fit_transform(X_train)\n",
    "X_test_set = tf_idf_update.transform(X_test)\n",
    "print(\"LogisticRegression no param__________________________________\")\n",
    "naive_bayes = LogisticRegression()\n",
    "naive_bayes.fit(X_train_set, Y_train)\n",
    "pred = naive_bayes.predict(X_test_set)\n",
    "print('\\n accuracy score: ', accuracy_score(Y_test, pred))\n",
    "print(classification_report(Y_test, pred, zero_division=0))\n",
    "print(\"_____________________________________________________________\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression with param________________________________\n",
      "\n",
      " accuracy score:  0.8235294117647058\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.83      1.00      0.91        10\n",
      "HAMILTON OR MADISON       0.75      1.00      0.86         3\n",
      "                JAY       1.00      0.50      0.67         2\n",
      "            MADISON       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.82        17\n",
      "          macro avg       0.65      0.62      0.61        17\n",
      "       weighted avg       0.74      0.82      0.76        17\n",
      "\n",
      "_____________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(\"LogisticRegression with param________________________________\")\n",
    "naive_bayes = LogisticRegression(solver='newton-cg',warm_start=\"True\", multi_class='multinomial',class_weight='balanced', C = 0.8)\n",
    "naive_bayes.fit(X_train_set, Y_train)\n",
    "pred = naive_bayes.predict(X_test_set)\n",
    "print('\\n accuracy score: ', accuracy_score(Y_test, pred))\n",
    "print(classification_report(Y_test, pred, zero_division=0))\n",
    "print(\"_____________________________________________________________\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st MLPClassifier with param_____________________________________\n",
      "\n",
      " accuracy score: 0.8235294117647058\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.83      1.00      0.91        10\n",
      "HAMILTON OR MADISON       0.75      1.00      0.86         3\n",
      "                JAY       1.00      0.50      0.67         2\n",
      "            MADISON       0.00      0.00      0.00         2\n",
      "\n",
      "           accuracy                           0.82        17\n",
      "          macro avg       0.65      0.62      0.61        17\n",
      "       weighted avg       0.74      0.82      0.76        17\n",
      "\n",
      "2nd MLPClassifier with param_____________________________________\n",
      "\n",
      " accuracy score: 0.6470588235294118\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.71      1.00      0.83        10\n",
      "HAMILTON OR MADISON       0.00      0.00      0.00         3\n",
      "                JAY       0.00      0.00      0.00         2\n",
      "            MADISON       0.33      0.50      0.40         2\n",
      "\n",
      "           accuracy                           0.65        17\n",
      "          macro avg       0.26      0.38      0.31        17\n",
      "       weighted avg       0.46      0.65      0.54        17\n",
      "\n",
      "3rd MLPClassifier with param_____________________________________\n",
      "\n",
      " accuracy score: 0.8823529411764706\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "           HAMILTON       0.83      1.00      0.91        10\n",
      "HAMILTON OR MADISON       1.00      1.00      1.00         3\n",
      "                JAY       1.00      0.50      0.67         2\n",
      "            MADISON       1.00      0.50      0.67         2\n",
      "\n",
      "           accuracy                           0.88        17\n",
      "          macro avg       0.96      0.75      0.81        17\n",
      "       weighted avg       0.90      0.88      0.87        17\n",
      "\n",
      "_____________________________________________________________\n",
      "my best precision is 0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "print(\"1st MLPClassifier with param_____________________________________\")\n",
    "naive_bayes = MLPClassifier(random_state=1, activation = 'tanh', learning_rate = 'invscaling', max_iter= 300)\n",
    "naive_bayes.fit(X_train_set, Y_train)\n",
    "pred_max = naive_bayes.predict(X_test_set)\n",
    "accur_max = accuracy_score(Y_test, pred)\n",
    "print(f'\\n accuracy score: {accur_max}')\n",
    "print(classification_report(Y_test, pred, zero_division=0))\n",
    "\n",
    "print(\"2nd MLPClassifier with param_____________________________________\")\n",
    "naive_bayes = MLPClassifier(random_state=1, activation = 'tanh', hidden_layer_sizes= (25,11,7,5,3,), learning_rate = 'invscaling', max_iter= 500)\n",
    "naive_bayes.fit(X_train_set, Y_train)\n",
    "pred = naive_bayes.predict(X_test_set)\n",
    "accur = accuracy_score(Y_test, pred)\n",
    "print(f'\\n accuracy score: {accur}')\n",
    "print(classification_report(Y_test, pred, zero_division=0))\n",
    "\n",
    "if accur>accur_max:\n",
    "    accur_max = accur\n",
    "\n",
    "\n",
    "print(\"3rd MLPClassifier with param_____________________________________\")\n",
    "naive_bayes = MLPClassifier(random_state=1, activation = 'tanh',hidden_layer_sizes= (45,11,2,), learning_rate = 'invscaling', max_iter= 1500)\n",
    "naive_bayes.fit(X_train_set, Y_train)\n",
    "pred = naive_bayes.predict(X_test_set)\n",
    "accur = accuracy_score(Y_test, pred)\n",
    "print(f'\\n accuracy score: {accur}')\n",
    "print(classification_report(Y_test, pred, zero_division=0))\n",
    "print(\"_____________________________________________________________\")\n",
    "\n",
    "if accur>accur_max:\n",
    "    accur_max = accur\n",
    "\n",
    "print(f\"My best precision is {accur_max}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}